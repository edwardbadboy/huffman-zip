huffman压缩和解压缩
通过huffman树可以构造huffman编码，本程序实现使用huffman编码压缩和解压缩程序。

1、huffman树、词汇表、编码表
本压缩程序是面向字节流文件的，1字节能存储0到255的值，一共256种可能。可以让程序把这256种可能作为256个单词来构造huffman树。

另外，有的文件里面可能不一定出现所有的256种可能，比如打开记事本，只输入“111111回车”，那就只有2个单词，一个是1，一个是回车。所以我们需要扫描整个文件，把出现过的单词和其次数记录下来，变成一个词汇表，然后次数作为权重，创建huffman树。然后通过huffman树，为每个单词创建一个huffman编码，所有的编码放在一起便于查询，作为编码表。这样在遇到某个单词的时候，直接从编码表里查出对应编码写到输出文件里就行。就是压缩的过程了。

解压缩的过程就正好相反，需要从文件中读取编码后的内容，反查编码表，得到原来的内容。一般来说，设计一种数据结构能正查又能反查的是很麻烦的，所以要闭开反查编码表，想别的办法得到原来的内容。其实只要有huffman树，拿到编码后的内容以后，按找此内容从树根走到叶子，叶子就是原来的内容，这样就不用反查编码表了。

所以压缩的过程是，扫描文件构造词汇表，创建huffman树和编码表，通过查编码表把文件压缩后输出。解压缩的或成是，不断的读压缩后的内容，按照此内容从huffman树的根走到叶子，输出叶子内容，然后又从根开始走。

2、比特流
huffman编码后的内容的比特数可能达不到8，也就填不满一个字节，也就是可能把原来1个字节的内容缩短成几个比特。那么如果有两个被编码后的单词，一个是3比特，一个是7比特，加起来一共是10比特，占一个字节又2比特。可是我们的标准库和平时在程序里都是只能针对字节作运算，像这种不和字节对齐的比特输出输入是很麻烦的。所以需要一种工具叫做比特流，用来帮助我们1比特1比特的输入和输出。可以自己写比特流程序，但是因为这个需求很多地方都要用到，所以可以用别人现成写好的。我们写huffman压缩程序的本意也是用来熟悉huffman算法，所以比特流不是重点锻炼的目的，因此用现成的就可以了。

标准库里没有比特流工具，所以我在网上搜索了一下，在
http://assassinationscience.com/johncostella/bitstream/
找到了一个开源的比特流库。

阅读了他的文档Bitstream.Manual.pdf，很简单，一下就学会了。使用的时候只需要把Bitstream.imp.h和Bitstream.h放在我们的cpp文件同一目录下，然后在cpp里include一下Bitstream.imp.h。编译的时候直接编译cpp文件就行。

3、压缩文件格式的设计
还需要考虑的一个问题是压缩文件格式的设计。为了区别我们压缩过的文件和一般文件，最好在压缩文件的头部写一些特殊的标志。另外，一般来说，压缩完一个文件后，程序要关掉，把压缩文件传给别人以后，再启动程序进行解压。这就意味着关掉程序以后，huffman树、词汇表和编码表都销毁了。因此为了能够解压缩，要把huffman树和词汇表作为额外的内容存到压缩文件里。并且要存到压缩文件的头部，否则就不知道怎么解压了。另外刚才提到，编码表在解压的时候没用，所以不用存下来。

另外，如果是通过比特流输出，最后输出的内容的比特数可能不是8的整数，但是操作系统存放文件是按字节为单位的。所以在压缩文件的最后一个字节里面，有一部分可能是我们的内容，剩下的是系统自动填充的没用的内容，不应该作为压缩数据处理，应该丢弃。这样我们就需要记录一下，在压缩的时候，到底输出了多少个比特。解压缩的时候就读出来这个数字，解压完这么多个比特以后，就不再继续解压缩了。

因此压缩文件格式设计如下：
特殊的标志
huffman树
词汇表
压缩内容的比特数
实际的压缩文件内容

在实际的压缩文件内容之前的这些东西都是必须的，否则没法解压缩。这些都是开销。如果待压缩的文件很小，那么这些开销本身都比压缩过的文件大了，就没必要压缩了。

4、文件的binary模式
使用2进制模式的时候，要自己编程精确的把内存中的数据结构写到文件里去。代码里的write_XXX就是做这些事情的。

另外，对于数组，我们可以直接写到文件里去。如果是树或者链表什么的就很麻烦了。因为文件在逻辑上是连续的区域，数组也是连续的，所以可以直接写，而树和链表在内存中是不连续的，是通过指针连起来的，每个节点在内存里的位置都不一样。所以如果要把树写到文件里，就要首先按某种顺序遍历这棵树，把每个节点依次写进去，同时还要记录节点之间的连接关系。因为在内存中是通过指针来记录这种连接关系的，而到了文件中，指针就失效了，所以要另外想办法存储这种连接关系。将来加载文件的时候，再恢复这种连接关系，重建出来的树的每个节点在内存中和原来的树肯定就不一样了，但是逻辑上的连接关系应该还是一样的，这样就行了。

因为存储树很麻烦，所以我是用树组来模拟树的。另外在我的数据结构的书里，huffman树的表示和构造本身就是通过数组模拟的，这个算法也很简单，所以我就用了这个方案。

5、压缩的效果
huffman算法对单词的权重相差悬殊文件压缩比较有效。可以试一下red.txt（红楼梦），因为红楼梦里什么字都有，并且大多数出现的频率并不悬殊，因此压缩效果一般。另外还有一个systags，这个也可以试，会发现单词的频率相差很悬殊，压缩效果比红楼梦好。如果是每个单词出现频率差不多的文件，甚至会出现压缩后的文件还比原来文件大的情况。这是huffman算法本身的缺陷所决定的。

另外在windows上vs2005编译在调试模式下运行程序，压缩文件会很慢，如果是release模式，就很快。在Linux下用g++用默认参数编译，运行速度一般。

6、每个文件的作用
huffman_zip_heap.cpp、huffman_zip.cpp、Bitstream.h、Bitstream.imp.h是代码。huffman_zip_heap与huffman_zip的区别是，在构造huffman树时，前者使用了优先队列去寻找最小的两个根节点。
test_resource下的red.txt、tags、systags是测试用的文件，可以用来测试压缩效果，benchmark是用来测试压缩速度的脚本。
Bitstream.Manual.pdf是Bitstream的使用手册。
执行make可以编译程序，执行make test可以测试程序速度。
